# -*- coding: utf-8 -*-
"""CNN - Mnist/VGG16

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dcevAr0DfIAyTLti_qEXf1NfpX53HaKW
"""

#IMPORTO LIBRERIE
import numpy as np
from keras.datasets import mnist
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import img_to_array, array_to_img
from keras.utils import np_utils
from keras.applications import VGG16;
from keras.applications.vgg16 import preprocess_input
from keras import Input
from keras import Model
from keras.models import Sequential
from keras.layers import Dense
import matplotlib.pyplot as plt

#IMPORTO DATASET â†’ FASHION MNIST
(X_train, y_train), (X_test, y_test) = mnist.load_data()

X = np.concatenate((X_train, X_test))
y = np.concatenate((y_train, y_test))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

#calcolo numero pixel
n_pixel = X_train.shape[1] * X_train.shape[2] #28*28=784

#trasformo il vettore
X_train = X_train.reshape(X_train.shape[0], n_pixel)
X_test = X_test.reshape(X_test.shape[0], n_pixel)

#DIVIDO IN 3 CANALI (vgg16 richiede immagini colorate (rgb))
X_train=np.dstack([X_train]*3)
X_test=np.dstack([X_test]*3)

#immagini dataset mnist 28*28
X_train = X_train.reshape(X_train.shape[0], 28,28,3)
X_test= X_test.reshape (X_test.shape[0],28,28,3)

#rimodello le immagini 48*48 x VGG16
X_train = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in X_train])
X_test = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in X_test])

#normalizzo i valori (e traformo in float)
X_train = X_train / 255
X_test = X_test / 255
X_train= X_train.astype('float32')
X_test= X_test.astype('float32')

#codifica one hot encode
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)
# shape[1] lunghezza stringa=numero di classi (10)
n_classi = y_train.shape[1]

X_train.shape, X_test.shape, y_train.shape, y_test.shape

#preprocessing input x vgg16
X_train = preprocess_input(X_train)
X_test =preprocess_input(X_test)

"""VGG16"""

conv_base = VGG16(weights='imagenet',
                  include_top=False, 
                  input_shape=(48, 48, 3)
                 )
conv_base.summary()

X_train= conv_base.predict(np.array(X_train), batch_size=16, verbose=1)
X_test= conv_base.predict(np.array(X_test), batch_size=16, verbose=1)

X_train.shape, X_test.shape

X_train=np.reshape(X_train, (X_train.shape[0], 512))
X_test=np.reshape(X_test, (X_test.shape[0], 512))

model = Sequential()
#layer
model.add(Dense(500, input_dim=512, activation='relu')) #primo strato nascosto
model.add(Dense(10, activation='softmax'))#layer di output

model.summary()

#Compilo modello
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

#progress=model.evaluate(X_test, y_test, batch_size=256)
progress=model.fit(X_train, y_train, validation_data=(X_test, y_test), validation_split=0.3, epochs=10, batch_size=256, shuffle=True)

"""Perdita accuratezza (accuracy)"""

plt.plot(progress.history['accuracy'])
plt.plot(progress.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Perdita dell'errore (loss)"""

plt.plot(progress.history['loss'])
plt.plot(progress.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()