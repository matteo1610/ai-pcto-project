# -*- coding: utf-8 -*-
"""DNN - dataset MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GZr4eU6h6ejZKekg7F8zxnvIsMFg4c73

Importo le librerie
"""

import numpy as np

from random import randint

from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils
from keras import Input
from keras import Model
from keras.datasets import mnist
from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt

"""Importo dataset â†’ mnist"""

#Importo mnist
(X_train, y_train), (X_test, y_test) = mnist.load_data()
#concateno
X = np.concatenate((X_train, X_test))
y = np.concatenate((y_train, y_test))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

#TEST PER VEDERE IL CONTENUTO DEL DATASET
#Visualizzo 4 cifre random
#for i in range(4):
#    plt.subplot(2, 2, (i + 1))
    #in shape[0] ci sono il numero di cifre del dataset
#    plt.imshow(X_train[randint(0, X_train.shape[0])], cmap=plt.get_cmap('gray'))
#plt.show()

#in shape[1] ci sono le dimensioni in pixel di y (28)
#in shape[2] ci sono le dimensioni in pixel di x (28)
#in shape[0] ci sono il numero di cifre del dataset (train=49000 e test=21000)

#calcolo numero pixel
n_pixel = X_train.shape[1] * X_train.shape[2] #28*28=784

#trasformo il vettore
X_train = X_train.reshape(X_train.shape[0], n_pixel)
X_test = X_test.reshape(X_test.shape[0], n_pixel)

X_train.shape, X_test.shape

#normalizzo i valori
X_train = X_train / 255
X_test = X_test / 255
X_train= X_train.astype('float32')
X_test= X_test.astype('float32')

#codifica one hot encode (consente di identificare la classe di appartenenza con 
#una stringa posizionale di cifre 0 e 1 lunga quanto il numero di classi)
y_train = np_utils.to_categorical(y_train)
y_test = np_utils.to_categorical(y_test)
# shape[1] lunghezza stringa=numero di classi (10)
n_classi = y_train.shape[1]

"""Definisco la mia rete neurale"""

#creo modello
model = Sequential()
#layer
model.add(Dense(500, input_dim=n_pixel, activation='relu')) #primo strato nascosto
#model.add(Dense(400, activation='relu'))
model.add(Dense(300, activation='relu'))
#model.add(Dense(200, activation='relu'))
model.add(Dense(100, activation='relu'))
model.add(Dense(10, activation='softmax'))#layer di output

model.summary()

#Compilo modello
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""Alleno la mia rete neurale"""

progress=model.fit(X_train, y_train, validation_data=(X_test, y_test), validation_split=0.3, epochs=10, batch_size=256, shuffle=True)

"""Perdita accuratezza (accuracy)"""

plt.plot(progress.history['accuracy'])
plt.plot(progress.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Perdita dell'errore (loss)"""

plt.plot(progress.history['loss'])
plt.plot(progress.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()